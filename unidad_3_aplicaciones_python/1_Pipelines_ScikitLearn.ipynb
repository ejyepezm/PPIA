{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejyepezm/PPIA/blob/main/unidad_3_aplicaciones_python/1_Pipelines_ScikitLearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# üíä C√°psula 1: El Modelo Robusto (ML Pipelines)\n",
        "**Tema:** Scikit-learn Pipelines, ColumnTransformer y Prevenci√≥n de Data Leakage."
      ],
      "metadata": {
        "id": "75wDwRLX0v1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. El enemigo silencioso: Data Leakage\n",
        "\n",
        "Cuando entrenas un modelo, sigues pasos: Imputar nulos -> Escalar datos -> Entrenar.\n",
        "El error novato #1 es hacer esto:\n",
        "1.  Escalar TODO el dataset.\n",
        "2.  Dividir en Train/Test.\n",
        "\n",
        "**¬øEl problema?** Al escalar todo junto, el conjunto de Test (el futuro) \"contamin√≥\" el promedio y la desviaci√≥n est√°ndar del conjunto de Train. Tu modelo sabe cosas del futuro que no deber√≠a saber.\n",
        "\n",
        "### La Soluci√≥n: Scikit-learn Pipeline\n",
        "Un `Pipeline` encadena estos pasos en un solo objeto.\n",
        "*   Cuando llamas `fit()`: Aprende los promedios SOLO de los datos de entrenamiento.\n",
        "*   Cuando llamas `predict()`: Aplica esas transformaciones guardadas a los nuevos datos autom√°ticamente.\n",
        "\n",
        "**ColumnTransformer:** Nos permite aplicar transformaciones diferentes a columnas num√©ricas (Escalar) y categ√≥ricas (OneHotEncoding) en el mismo flujo."
      ],
      "metadata": {
        "id": "_90OEFt80-fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- DATOS DE JUGUETE ---\n",
        "# Imaginemos datos m√©dicos: Edad (num√©rico) y Resultado (Target)\n",
        "data = pd.DataFrame({\n",
        "    'Edad': [25, 30, 45, 35, 60, None, 22, 50], # Tiene un nulo\n",
        "    'Colesterol': [180, 200, 240, 210, 290, 190, 170, 250],\n",
        "    'Enfermedad': [0, 0, 1, 0, 1, 0, 0, 1]\n",
        "})\n",
        "\n",
        "# Dividimos ANTES de tocar nada (Regla de oro)\n",
        "X = data[['Edad', 'Colesterol']]\n",
        "y = data['Enfermedad']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "print(\"--- CONSTRUYENDO PIPELINE ---\")\n",
        "\n",
        "# Creamos el tubo de procesamiento\n",
        "# Paso 1: Rellenar nulos con la media\n",
        "# Paso 2: Escalar (StandardScaler)\n",
        "# Paso 3: Modelo (Regresi√≥n Log√≠stica)\n",
        "pipeline_medico = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Entrenamos TODO el flujo de una vez\n",
        "pipeline_medico.fit(X_train, y_train)\n",
        "print(\"‚úÖ Pipeline entrenado exitosamente.\")\n",
        "\n",
        "# Predecimos (El pipeline se encarga de imputar y escalar el test set autom√°ticamente)\n",
        "predicciones = pipeline_medico.predict(X_test)\n",
        "print(f\"Predicciones: {predicciones}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, predicciones):.2f}\")"
      ],
      "metadata": {
        "id": "rN3s6qLt1ARh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî• Micro-Desaf√≠o: El \"ColumnTransformer\"\n",
        "\n",
        "En la vida real, los datos son mixtos. Tienes columnas num√©ricas (Edad) y categ√≥ricas (Ciudad). No puedes escalar una ciudad (\"Madrid\"), y no puedes hacer OneHotEncoding de una edad.\n",
        "\n",
        "**Tu Misi√≥n:**\n",
        "Tienes un dataset de Clientes con:\n",
        "*   Num√©ricas: `Gasto`, `Visitas`\n",
        "*   Categ√≥ricas: `Genero`\n",
        "\n",
        "Construye un **Preprocesador H√≠brido** usando `ColumnTransformer`:\n",
        "1.  A las num√©ricas: Aplica `SimpleImputer` (media) y `StandardScaler`.\n",
        "2.  A las categ√≥ricas: Aplica `SimpleImputer` (moda/most_frequent) y `OneHotEncoder`.\n",
        "3.  Une todo en un Pipeline final con un modelo `RandomForestClassifier`."
      ],
      "metadata": {
        "id": "OaI-nepB1DKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Datos mixtos\n",
        "df_reto = pd.DataFrame({\n",
        "    'Gasto': [100, 200, None, 300, 150],\n",
        "    'Visitas': [1, 5, 2, 8, 3],\n",
        "    'Genero': ['F', 'M', 'F', None, 'M'],\n",
        "    'Compra': [0, 1, 0, 1, 0]\n",
        "})\n",
        "\n",
        "X = df_reto.drop('Compra', axis=1)\n",
        "y = df_reto['Compra']\n",
        "\n",
        "# Definimos qu√© columnas son cu√°les\n",
        "cols_num = ['Gasto', 'Visitas']\n",
        "cols_cat = ['Genero']\n",
        "\n",
        "# --- TU C√ìDIGO AQU√ç ---\n",
        "\n",
        "# 1. Pipeline para Num√©ricas\n",
        "pipe_num = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# 2. Pipeline para Categ√≥ricas\n",
        "pipe_cat = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore')) # handle_unknown es clave en producci√≥n\n",
        "])\n",
        "\n",
        "# 3. El Transformador de Columnas (El cerebro que divide)\n",
        "# TODO: Completa el ColumnTransformer\n",
        "# preprocesador = ColumnTransformer([\n",
        "#     ('num', pipe_num, cols_num),\n",
        "#     ('cat', ..., ...)\n",
        "# ])\n",
        "preprocesador = None # REEMPLAZA ESTO\n",
        "\n",
        "# 4. Pipeline Final (Preprocesador + Modelo)\n",
        "# TODO: Crea el Pipeline final usando RandomForestClassifier\n",
        "pipeline_final = None # REEMPLAZA ESTO\n",
        "\n",
        "# --- VALIDACI√ìN (No tocar) ---\n",
        "try:\n",
        "    if pipeline_final:\n",
        "        pipeline_final.fit(X, y)\n",
        "        print(\"‚úÖ ¬°√âxito! El pipeline h√≠brido entren√≥ correctamente.\")\n",
        "        print(\"Clases del modelo:\", pipeline_final.named_steps['model'].classes_)\n",
        "    else:\n",
        "        print(\"‚ùå Falta definir el pipeline_final.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"Pista: Revisa los nombres de las columnas y los pasos del ColumnTransformer.\")"
      ],
      "metadata": {
        "id": "w8HdGHr01FPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}