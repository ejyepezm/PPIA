{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejyepezm/PPIA/blob/main/unidad_3_aplicaciones_python/2_MLflow_Tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# üíä C√°psula 2: El Detective de Experimentos (MLflow)\n",
        "**Tema:** Tracking de Experimentos, Registro de M√©tricas y Comparaci√≥n de Modelos."
      ],
      "metadata": {
        "id": "3AzseURG1Sv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. El Caos de los Hiperpar√°metros\n",
        "\n",
        "En ML, nunca entrenas un solo modelo. Pruebas cientos:\n",
        "*   \"RandomForest con 10 √°rboles\"\n",
        "*   \"RandomForest con 50 √°rboles\"\n",
        "*   \"Con escalado vs sin escalado\"\n",
        "\n",
        "Si anotas esto en un Excel o conf√≠as en tu memoria, perder√°s el mejor modelo.\n",
        "\n",
        "### La Soluci√≥n: MLflow\n",
        "MLflow es una herramienta (Open Source) que act√∫a como un \"Diario de Laboratorio\" autom√°tico.\n",
        "Dentro de un bloque `with mlflow.start_run():`, todo lo que hagas queda guardado para siempre:\n",
        "*   `log_param()`: Qu√© configuraci√≥n usaste (ej. n_estimators=100).\n",
        "*   `log_metric()`: Qu√© resultado obtuviste (ej. accuracy=0.95).\n",
        "*   `log_model()`: Guarda el archivo del modelo (.pkl) autom√°ticamente."
      ],
      "metadata": {
        "id": "jYO62iSD1Yj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos MLflow (silencioso para no ensuciar la salida)\n",
        "!pip install mlflow -q\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Preparamos datos (Iris)\n",
        "data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2)\n",
        "\n",
        "# Configuraci√≥n b√°sica (Local)\n",
        "mlflow.set_experiment(\"Experimento_Iris_Clase\")"
      ],
      "metadata": {
        "id": "SU4vkJZH1buR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DEMOSTRACI√ìN: Un solo experimento ---\n",
        "\n",
        "print(\"Iniciando entrenamiento...\")\n",
        "\n",
        "# Iniciamos el \"Run\" (La ejecuci√≥n)\n",
        "with mlflow.start_run(run_name=\"Modelo_Bosque_Peque√±o\"):\n",
        "\n",
        "    # 1. Definimos par√°metros\n",
        "    n_arboles = 10\n",
        "    profundidad = 3\n",
        "\n",
        "    # 2. Registramos par√°metros (Para no olvidarlos)\n",
        "    mlflow.log_param(\"n_estimators\", n_arboles)\n",
        "    mlflow.log_param(\"max_depth\", profundidad)\n",
        "\n",
        "    # 3. Entrenamos\n",
        "    clf = RandomForestClassifier(n_estimators=n_arboles, max_depth=profundidad)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # 4. Evaluamos\n",
        "    predicciones = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, predicciones)\n",
        "\n",
        "    # 5. Registramos la m√©trica (El resultado)\n",
        "    print(f\"Accuracy obtenido: {acc}\")\n",
        "    mlflow.log_metric(\"accuracy\", acc)\n",
        "\n",
        "    # 6. Guardamos el modelo (Artefacto)\n",
        "    mlflow.sklearn.log_model(clf, \"modelo_random_forest\")\n",
        "\n",
        "print(\"‚úÖ Experimento registrado en MLflow.\")"
      ],
      "metadata": {
        "id": "OjxkP0lw1dvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî• Micro-Desaf√≠o: El Bucle de Optimizaci√≥n\n",
        "\n",
        "Queremos encontrar el n√∫mero √≥ptimo de √°rboles para nuestro Bosque Aleatorio.\n",
        "Probar manualmente es aburrido.\n",
        "\n",
        "**Tu Misi√≥n:**\n",
        "1.  Crea una lista de configuraciones: `lista_arboles = [10, 50, 100, 200]`.\n",
        "2.  Haz un bucle `for` que recorra esa lista.\n",
        "3.  Dentro del bucle, inicia un `mlflow.start_run()`.\n",
        "4.  Entrena el modelo con ese n√∫mero de √°rboles, registra el par√°metro y la m√©trica de accuracy.\n",
        "5.  **Bonus:** Al final, usa `mlflow.search_runs()` para mostrar un DataFrame con todos los resultados y ver cu√°l gan√≥."
      ],
      "metadata": {
        "id": "Z8AtUW5f1fvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de hiperpar√°metros a probar\n",
        "lista_arboles = [5, 20, 50, 100]\n",
        "\n",
        "print(\"üß™ Iniciando b√∫squeda de hiperpar√°metros...\")\n",
        "\n",
        "for n in lista_arboles:\n",
        "    # --- TU C√ìDIGO AQU√ç ---\n",
        "    # TODO: Inicia el run con un nombre din√°mico ej: f\"Run_{n}_arboles\"\n",
        "    with mlflow.start_run(run_name=f\"Run_{n}_arboles\"):\n",
        "\n",
        "        # TODO: Loguea el par√°metro n_estimators\n",
        "\n",
        "        # Entrenamiento (Te lo doy hecho)\n",
        "        model = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "        # TODO: Loguea la m√©trica accuracy\n",
        "\n",
        "        print(f\"--> Arboles: {n} | Accuracy: {acc:.4f}\")\n",
        "\n",
        "# --- VALIDACI√ìN Y AN√ÅLISIS ---\n",
        "print(\"\\nüìä Resumen de Experimentos (Pandas DataFrame):\")\n",
        "# MLflow nos permite bajar los resultados como tabla\n",
        "resultados = mlflow.search_runs()\n",
        "print(resultados[['params.n_estimators', 'metrics.accuracy']].sort_values(by='metrics.accuracy', ascending=False))"
      ],
      "metadata": {
        "id": "1W6YK-mY1hfm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}